<h1 align="center">DPDFNet: Boosting DeepFilterNet2 via Dual-Path RNN</h1>
<br></br>

<div align="center">

[![Project Page](https://img.shields.io/badge/Project-Page-orange)](https://ceva-ip.github.io/DPDFNet/)
[![arXiv Paper](https://img.shields.io/badge/arXiv-Paper-b31b1b)](https://arxiv.org/abs/2512.16420)
[![ü§ó Hugging Face Models](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-yellow)](https://huggingface.co/Ceva-IP/DPDFNet)
[![ü§ó Hugging Face Dataset](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Dataset-yellowgreen)](https://huggingface.co/datasets/Ceva-IP/DPDFNet_EvalSet)

</div>

<p align="center">
  <sub><em><strong>--- Official implementation for the DPDFNet paper (2025) ---</strong></em></sub>
</p>

## Abstract
We present DPDFNet, a causal single-channel speech enhancement model that extends the DeepFilterNet2 architecture with dual-path blocks in the encoder, strengthening long-range temporal and cross-band modeling while preserving the original enhancement framework. In addition, we demonstrate that adding a loss component to mitigate over-attenuation in the enhanced speech, combined with a fine-tuning phase tailored for ‚Äúalways-on‚Äù applications, leads to substantial improvements in overall model performance. To compare our proposed architecture with a variety of causal open-source models, we created a new evaluation set comprising long, low-SNR recordings in 12 languages across everyday noise scenarios, better reflecting real-world conditions than commonly used benchmarks. On this evaluation set, DPDFNet delivers superior performance to other causal open-source models, including some that are substantially larger and more computationally demanding. We also propose a holistic metric named PRISM, a composite, scale-normalized aggregate of intrusive and non-intrusive metrics, which demonstrates clear scalability with the number of dual-path blocks. We further demonstrate on-device feasibility by deploying DPDFNet on Ceva-NeuPro‚Ñ¢-Nano edge NPUs. Results indicate that DPDFNet-4, our second-largest model, achieves real-time performance on NPN32 and runs even faster on NPN64, confirming that state-of-the-art quality can be sustained within strict embedded power and latency constraints.


---

## Repository Overview

This repo includes:
- **Offline enhancement** for a folder of WAV files (`enhance.py`)
- A **real-time microphone demo** with live spectrograms and A/B playback (`real_time_demo.py`)
- Pre-exported **TFLite models** expected under: `model_zoo/tflite/*.tflite`

### TFLite models

Place the `.tflite` files under:
```
model_zoo/tflite/
```

Use model names **without** the `.tflite` suffix in scripts (e.g., `dpdfnet4`, not `dpdfnet4.tflite`).

Supported model files:

| Model           | Params [M] | MACs [G] | TFLite Size [MB] | Intended Use                    |
| --------------- | :--------: | :------: | :--------------: | ------------------------------- |
| baseline.tflite |    2.31    |   0.36   |        8.5       | Fastest / lowest resource usage |
| dpdfnet2.tflite |    2.49    |   1.35   |       10.7       | Real-time / embedded devices    |
| dpdfnet4.tflite |    2.84    |   2.36   |       12.9       | Balanced performance            |
| dpdfnet8.tflite |    3.54    |   4.37   |       17.2       | Best enhancement quality        |

### Download models

Models are available on Hugging Face: https://huggingface.co/Ceva-IP/DPDFNet

Example download into the expected folder:
```bash
pip install -U "huggingface_hub[cli]"
mkdir -p model_zoo/tflite

huggingface-cli download Ceva-IP/DPDFNet \
  baseline.tflite dpdfnet2.tflite dpdfnet4.tflite dpdfnet8.tflite \
  --local-dir model_zoo/tflite \
  --local-dir-use-symlinks False
```

---

## Quick start

### Install (full: offline + real-time demo)
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### Install (lightweight: offline enhancement only)
If you only need `enhance.py` and want to avoid heavy GUI/audio/demo dependencies:
```bash
pip install numpy scipy librosa soundfile tqdm tflite-runtime
```

Both scripts look for models under `./model_zoo/tflite` by default.

---


## Offline Enhancement

Enhance all `*.wav` files in a folder (**non-recursive**) and write enhanced WAVs to an output folder:

```bash
python enhance.py   --noisy_dir /path/to/noisy_wavs   --enhanced_dir /path/to/output   --model_name dpdfnet8
```

What the script does:
- Loads audio (any sample rate), converts to **mono**, resamples to **16 kHz** for the model.
- Runs the model **frame-by-frame in streaming mode**.
- Resamples back to the original sample rate, and saves **mono PCM_16 WAV** outputs.

Output filenames are created as:
```
<original_stem>_<model_name>.wav
```

---

## Real-Time Microphone Demo

![Real-time DPDFNet demo screen shot](figures/live_demo.png "Real-time DPDFNet demo screen shot")

The real-time demo performs streaming enhancement on microphone input, displays **Noisy vs Enhanced** live spectrograms, and lets you switch playback between the two.

### Run
```bash
python real_time_demo.py
```

### Configure
Edit constants near the top of `real_time_demo.py`:
- `MODEL_NAME`: `baseline | dpdfnet2 | dpdfnet4 | dpdfnet8`

### Usage
- Speak into your microphone.
- Use the UI buttons to switch playback:
  - **Noisy**: plays raw mic input
  - **Enhanced**: plays model output
- The console prints **ms per frame** to help assess real-time performance.

---

## Metrics & Evaluation

To compute *intrusive* and *non-intrusive* metrics on our [DPDFNet EvalSet](https://huggingface.co/datasets/Ceva-IP/DPDFNet_EvalSet), we use the tools listed below. For aggregate quality reporting, we rely on PRISM, the scale‚Äënormalized composite metric introduced in the DPDFNet paper.

### Intrusive metrics: PESQ, STOI, SI-SNR
We provide a dedicated script, `pesq_stoi_sisnr_calc.py`, which computes **PESQ**, **STOI**, and **SI-SNR** for paired *reference* and *enhanced* audio. The script includes a built-in auto-alignment step that corrects small start-time offsets and drift between the reference and the enhanced signals before scoring, to ensure fair comparisons.

### Non-intrusive metrics
- **DNSMOS (P.835 & P.808)** - We use the **official** DNSMOS local inference script from the DNS Challenge repository: [`dnsmos_local.py`](https://github.com/microsoft/DNS-Challenge/blob/master/DNSMOS/dnsmos_local.py). Please follow their installation and model download instructions in that project before running.  
- **NISQA v2** - We use the **official** NISQA project: <https://github.com/gabrielmittag/NISQA>. Refer to their README for environment setup, pretrained model weights, and inference commands (*e.g.*, running `nisqa_predict.py` on a folder of WAVs).

## Citation
If you use this work, please cite the paper:

```bibtex
@article{rika2025dpdfnet,
  title   = {DPDFNet: Boosting DeepFilterNet2 via Dual-Path RNN},
  author  = {Rika, Daniel and Sapir, Nino and Gus, Ido},
  year    = {2025},
}
```

## License

Apache License 2.0. See [LICENSE](LICENSE).
